<!-- <div align="center"> -->

# DocsBlip

## Literatur

| Name     | Paper                                        | Category |
|----------|----------------------------------------------|----------|
| DocVQA   | DocVQA: A Dataset for VQA on Document Images | dataset  |
| HyperDoc |                                              | model    |
| Sammlungen | https://github.com/ym-xu/awesome-document-understanding-datasets  | repo    |
| DIVE-Doc | https://github.com/JayRay5/DIVE-Doc/blob/main/data/docvqa/utils.py  | repo    |

## Ansatz
- [x] Demo
- [ ] Datenvorverarbeitung
- [ ] Trainings- und Eval.-Pipeline
- [ ] OPT2 oder Vicuna Chat statt BART verwenden
- [ ] FT mit kontrastivem Loss und LM-Loss
- [ ] Attention-Schichten statt Proj. Schicht

## Referenzen
[1] https://arxiv.org/pdf/2301.12597
