{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7296143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kusuma/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import sys\n",
    "from src.models.docsblip_stage2 import DocsBlip\n",
    "from src.data.docvqa import generate_dataset, BatchContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa6b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(ckpt_path) -> torch.nn.Module:\n",
    "    config_path = os.path.join(ckpt_path, '.hydra/config.yaml')\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    model = hydra.utils.instantiate(config['model'])\n",
    "    pathlist = Path(ckpt_path).glob('**/*.ckpt')\n",
    "    filelist = [str(file) for file in pathlist]\n",
    "    weight_path = filelist[0]\n",
    "    ckpt = torch.load(weight_path, weights_only=False)#, map_location='cpu')\n",
    "    weight = ckpt['state_dict']\n",
    "    model.load_state_dict(weight, strict=False)\n",
    "    for n, p in model.named_parameters():\n",
    "        p.requires_grad = False\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee21f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertLMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.intermediate_query.dense.bias', 'bert.encoder.layer.0.intermediate_query.dense.weight', 'bert.encoder.layer.0.output_query.LayerNorm.bias', 'bert.encoder.layer.0.output_query.LayerNorm.weight', 'bert.encoder.layer.0.output_query.dense.bias', 'bert.encoder.layer.0.output_query.dense.weight', 'bert.encoder.layer.1.intermediate_query.dense.bias', 'bert.encoder.layer.1.intermediate_query.dense.weight', 'bert.encoder.layer.1.output_query.LayerNorm.bias', 'bert.encoder.layer.1.output_query.LayerNorm.weight', 'bert.encoder.layer.1.output_query.dense.bias', 'bert.encoder.layer.1.output_query.dense.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.intermediate_query.dense.bias', 'bert.encoder.layer.10.intermediate_query.dense.weight', 'bert.encoder.layer.10.output_query.LayerNorm.bias', 'bert.encoder.layer.10.output_query.LayerNorm.weight', 'bert.encoder.layer.10.output_query.dense.bias', 'bert.encoder.layer.10.output_query.dense.weight', 'bert.encoder.layer.11.intermediate_query.dense.bias', 'bert.encoder.layer.11.intermediate_query.dense.weight', 'bert.encoder.layer.11.output_query.LayerNorm.bias', 'bert.encoder.layer.11.output_query.LayerNorm.weight', 'bert.encoder.layer.11.output_query.dense.bias', 'bert.encoder.layer.11.output_query.dense.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.intermediate_query.dense.bias', 'bert.encoder.layer.2.intermediate_query.dense.weight', 'bert.encoder.layer.2.output_query.LayerNorm.bias', 'bert.encoder.layer.2.output_query.LayerNorm.weight', 'bert.encoder.layer.2.output_query.dense.bias', 'bert.encoder.layer.2.output_query.dense.weight', 'bert.encoder.layer.3.intermediate_query.dense.bias', 'bert.encoder.layer.3.intermediate_query.dense.weight', 'bert.encoder.layer.3.output_query.LayerNorm.bias', 'bert.encoder.layer.3.output_query.LayerNorm.weight', 'bert.encoder.layer.3.output_query.dense.bias', 'bert.encoder.layer.3.output_query.dense.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.intermediate_query.dense.bias', 'bert.encoder.layer.4.intermediate_query.dense.weight', 'bert.encoder.layer.4.output_query.LayerNorm.bias', 'bert.encoder.layer.4.output_query.LayerNorm.weight', 'bert.encoder.layer.4.output_query.dense.bias', 'bert.encoder.layer.4.output_query.dense.weight', 'bert.encoder.layer.5.intermediate_query.dense.bias', 'bert.encoder.layer.5.intermediate_query.dense.weight', 'bert.encoder.layer.5.output_query.LayerNorm.bias', 'bert.encoder.layer.5.output_query.LayerNorm.weight', 'bert.encoder.layer.5.output_query.dense.bias', 'bert.encoder.layer.5.output_query.dense.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.intermediate_query.dense.bias', 'bert.encoder.layer.6.intermediate_query.dense.weight', 'bert.encoder.layer.6.output_query.LayerNorm.bias', 'bert.encoder.layer.6.output_query.LayerNorm.weight', 'bert.encoder.layer.6.output_query.dense.bias', 'bert.encoder.layer.6.output_query.dense.weight', 'bert.encoder.layer.7.intermediate_query.dense.bias', 'bert.encoder.layer.7.intermediate_query.dense.weight', 'bert.encoder.layer.7.output_query.LayerNorm.bias', 'bert.encoder.layer.7.output_query.LayerNorm.weight', 'bert.encoder.layer.7.output_query.dense.bias', 'bert.encoder.layer.7.output_query.dense.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.intermediate_query.dense.bias', 'bert.encoder.layer.8.intermediate_query.dense.weight', 'bert.encoder.layer.8.output_query.LayerNorm.bias', 'bert.encoder.layer.8.output_query.LayerNorm.weight', 'bert.encoder.layer.8.output_query.dense.bias', 'bert.encoder.layer.8.output_query.dense.weight', 'bert.encoder.layer.9.intermediate_query.dense.bias', 'bert.encoder.layer.9.intermediate_query.dense.weight', 'bert.encoder.layer.9.output_query.LayerNorm.bias', 'bert.encoder.layer.9.output_query.LayerNorm.weight', 'bert.encoder.layer.9.output_query.dense.bias', 'bert.encoder.layer.9.output_query.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BertLMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "BertLMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = 'logs/docsblip_stage2/runs/2025-11-11_22-29-28'\n",
    "model = init_model(ckpt_path)\n",
    "model.eval()\n",
    "encoder_tokenizer = AutoTokenizer.from_pretrained(\"SCUT-DLVCLab/lilt-roberta-en-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20ec237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1591.98it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = generate_dataset(\n",
    "    annotation_path=\"data/spdocvqa_qas/val_v1.0_withQT.json\",\n",
    "    ocr_path=\"data/ocr\",\n",
    "    subset_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e22e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7c18985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id_txpp0227_10'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4cb13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_tokens = encoder_tokenizer(sample['words'], boxes=sample['bbox'], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33f73e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is â€˜presidingâ€™ TRRF GENERAL SESSION (PART 1)?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = sample['question']\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40ee7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = BatchContainer(\n",
    "    input_ids=encoded_tokens['input_ids'],\n",
    "    input_attention_mask=encoded_tokens['attention_mask'],\n",
    "    input_bbox=encoded_tokens['bbox'],\n",
    "    targets=sample['answer'],\n",
    "    questions=sample['question'],\n",
    "    words=sample['words'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b2256bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE GAME.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_answer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a88540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the name of the fashion wear/clothing advertise\n",
      "Assistant: THE GAME.\n",
      "the game\n",
      "\n",
      "these as this page\n",
      "\n",
      "\n",
      "GT: wills lifestyle\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[12]\n",
    "inputs = BatchContainer(\n",
    "    input_ids=encoded_tokens['input_ids'],\n",
    "    input_attention_mask=encoded_tokens['attention_mask'],\n",
    "    input_bbox=encoded_tokens['bbox'],\n",
    "    targets=sample['answer'],\n",
    "    questions=sample['question'],\n",
    "    words=sample['words'],\n",
    ")\n",
    "question = sample['question']\n",
    "answer = model.generate_answer(inputs)[0]\n",
    "dialog = f\"\"\"User: {question}\\nAssistant: {answer}\"\"\"\n",
    "print(dialog)\n",
    "print(f\"GT: {sample['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4d92268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How many lint/string pieces of matter is found in the core samples ?\n",
      "Assistant: the game\n",
      "Ð by the game.\n",
      "by the rest of this game\n",
      "\n",
      "GT: 22\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[33]\n",
    "inputs = BatchContainer(\n",
    "    input_ids=encoded_tokens['input_ids'],\n",
    "    input_attention_mask=encoded_tokens['attention_mask'],\n",
    "    input_bbox=encoded_tokens['bbox'],\n",
    "    targets=sample['answer'],\n",
    "    questions=sample['question'],\n",
    "    words=sample['words'],\n",
    ")\n",
    "question = sample['question']\n",
    "answer = model.generate_answer(inputs)[0]\n",
    "dialog = f\"\"\"User: {question}\\nAssistant: {answer}\"\"\"\n",
    "print(dialog)\n",
    "print(f\"GT: {sample['answer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4dbecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docsblip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
